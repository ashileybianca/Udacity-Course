{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training Neural Networks</h1>\n",
    "\n",
    "The network we built in the previous part isn't so smart, it doesn't know anything about our handwritten digits. Neural networks with non-linear activations work like universal function approximators. There is some function that maps your input to the output. For example, images of handwritten digits to class probabilities. The power of neural networks is that we can train them to approximate this function, and basically any function given enough data and compute time.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses in PyTorch\n",
    "\n",
    "Let's start by seeing how we calculate the loss with PyTorch. Through the `nn` module, PyTorch provides losses such as the cross-entropy loss (`nn.CrossEntropyLoss`). You'll usually see the loss assigned to `criterion`. As noted in the last part, with a classification problem such as MNIST, we're using the softmax function to predict class probabilities. With a softmax output, you want to use cross-entropy as the loss. To actually calculate the loss, you first define the criterion then pass in the output of your network and the correct labels.\n",
    "\n",
    "Something really important to note here. Looking at [the documentation for `nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss),\n",
    "\n",
    "> This criterion combines `nn.LogSoftmax()` and `nn.NLLLoss()` in one single class.\n",
    ">\n",
    "> The input is expected to contain scores for each class.\n",
    "\n",
    "This means we need to pass in the raw output of our network into the loss, not the output of the softmax function. This raw output is usually called the *logits* or *scores*. We use the logits because softmax gives you probabilities which will often be very close to zero or one but floating-point numbers can't accurately represent values near zero or one ([read more here](https://docs.python.org/3/tutorial/floatingpoint.html)). It's usually best to avoid doing calculations with probabilities, typically we use log-probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The MNIST datasets are hosted on yann.lecun.com that has moved under CloudFlare protection\n",
    "# Run this script to enable the datasets download\n",
    "# Reference: https://github.com/pytorch/vision/issues/1938\n",
    "\n",
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fazendo download do dataset do MNIST\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um DataLoader é uma classe em PyTorch que fornece uma interface conveniente para iterar sobre conjuntos de dados durante o treinamento ou teste de modelos de aprendizado de máquina, especialmente em tarefas de aprendizado supervisionado, como classificação ou regressão.\n",
    "\n",
    "Especificamente, um DataLoader é usado para carregar os dados de um conjunto de dados e agrupá-los em lotes (batches). Isso é útil porque durante o treinamento de modelos de aprendizado de máquina, os dados geralmente são processados em lotes, não de forma individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3507, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "# Construção da Rede Neural:\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "# Isso cria uma rede neural com três camadas lineares (fully connected) intercaladas com funções de ativação ReLU.\n",
    "\n",
    "# Definição da Função de Perda:\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Aqui, é definida a função de perda CrossEntropyLoss, que é comumente usada em\n",
    "# problemas de classificação multiclasse. Esta função de perda combina uma função de \n",
    "# softmax com a função de entropia cruzada (cross-entropy), que é uma medida de\n",
    "# quão bem o modelo de classificação está realizando. (logs)\n",
    "\n",
    "# Obtenção dos Dados de Treinamento:\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "# Aqui, iter(trainloader) cria um iterador para o trainloader, \n",
    "# que é o DataLoader que contém os dados de treinamento. \n",
    "# next(dataiter) obtém o próximo lote de dados de treinamento, \n",
    "# que consiste em imagens (images) e seus rótulos correspondentes (labels).\n",
    "\n",
    "# Processamento dos Dados:\n",
    "images = images.view(images.shape[0], -1)\n",
    "# Como as imagens estão no formato (batch_size, 1, 28, 28), esta linha redimensiona\n",
    "# as imagens para que elas tenham a forma (batch_size, 784), para que possam ser \n",
    "# usadas como entrada para a rede neural.\n",
    "\n",
    "# Passagem para Frente (Forward Pass):\n",
    "logits = model(images)\n",
    "# Isso realiza uma passagem para frente pela rede neural, onde as imagens\n",
    "# são passadas pela rede e as previsões (logits) são calculadas.\n",
    "\n",
    "# Calculate the loss with the logits and the labels\n",
    "# Cálculo da Perda:\n",
    "loss = criterion(logits, labels)\n",
    "# Aqui, a função de perda é calculada comparando as previsões (logits) com os \n",
    "# rótulos verdadeiros (labels). A função CrossEntropyLoss já inclui a aplicação da \n",
    "# função softmax e o cálculo da entropia cruzada, portanto, não é necessário aplicar \n",
    "# a função softmax explicitamente na saída do modelo.\n",
    "\n",
    "print(loss)\n",
    "# Imprime o valor da perda calculada para o lote de dados de treinamento atual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Exercise:` Construa um modelo que retorne o log-softmax como saída e calcule a perda utilizando a perda de log-verossimilhança negativa (negative log likelihood loss). Note que para nn.LogSoftmax e F.log_softmax, você precisará definir corretamente o argumento de palavra-chave dim. dim=0 calcula o softmax pelas linhas, de modo que cada coluna some para 1, enquanto dim=1 calcula pelas colunas, de modo que cada linha some para 1. Pense sobre o que você deseja que a saída seja e escolha dim apropriadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3164, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))  # Modificando a última camada para retornar log-softmax\n",
    "\n",
    "# Para cada linha (ou amostra) de logits, a log-softmax será calculada, garantindo que  a operação de \n",
    "# log-softmax normaliza os logits para que, após a exponenciação e a normalização, eles representem as\n",
    "# probabilidades logarítmicas para cada classe. Essas probabilidades estarão na faixa de 0 a 1\n",
    "\n",
    "# Portanto, nn.LogSoftmax(dim=1) é uma camada que aplica a operação de log-softmax aos logits de\n",
    "# saída da rede neural ao longo da dimensão especificada. Essa camada é comumente usada como a última \n",
    "# camada de uma rede neural em problemas de classificação, quando a saída da rede precisa ser convertida \n",
    "# em probabilidades normalizadas para cada classe.\n",
    "\n",
    "# TODO: Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "# With a log-softmax output, you want to use the negative log likelihood loss, nn.NLLLoss\n",
    "# Usando a perda de log-verossimilhança negativa\n",
    "\n",
    "### Run this to check your work\n",
    "# Get our data\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images) #log probabilidades\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os \"logits\" são os valores de saída brutos gerados pela última camada de uma rede neural antes da aplicação de uma função de ativação. Em problemas de classificação, os logits representam as pontuações associadas a cada classe possível.\n",
    "\n",
    "Os logits não representam diretamente as probabilidades de cada classe (por exemplo, de 0 a 9), mas sim uma medida da \"confiança\" da rede neural de que a entrada pertence a cada classe. Os valores de logits não são restritos ao intervalo de 0 a 1, como as probabilidades, e podem assumir qualquer valor real.\n",
    "\n",
    "Por exemplo, suponha que tenhamos um problema de classificação com 3 classes (A, B e C) e a saída da última camada da rede neural seja uma lista de logits [2.3, -1.1, 0.5]. Isso significa que a rede neural atribui uma \"pontuação\" de 2.3 para a classe A, -1.1 para a classe B e 0.5 para a classe C.\n",
    "\n",
    "Após a obtenção dos logits, aplicamos uma função de ativação para transformá-los em probabilidades. Uma função comum para isso é a função softmax, que normaliza os logits de forma que as probabilidades somem para 1. Portanto, os logits não representam diretamente as probabilidades de cada classe, mas sim as pontuações associadas a cada classe antes da normalização."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "\n",
    "Now that we know how to calculate a loss, how do we use it to perform backpropagation? Torch provides a module, `autograd`, for automatically calculating the gradients of tensors. We can use it to calculate the gradients of all our parameters with respect to the loss. Autograd works by keeping track of operations performed on tensors, then going backwards through those operations, calculating gradients along the way. To make sure PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set `requires_grad = True` on a tensor. You can do this at creation with the `requires_grad` keyword, or at any time with `x.requires_grad_(True)`.\n",
    "\n",
    "You can turn off gradients for a block of code with the `torch.no_grad()` content:\n",
    "```python\n",
    "x = torch.zeros(1, requires_grad=True)\n",
    ">>> with torch.no_grad():\n",
    "...     y = x * 2\n",
    ">>> y.requires_grad\n",
    "False\n",
    "```\n",
    "\n",
    "Also, you can turn on or off gradients altogether with `torch.set_grad_enabled(True|False)`.\n",
    "\n",
    "The gradients are computed with respect to some variable `z` with `z.backward()`. This does a backward pass through the operations that created `z`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## notas\n",
    "requires_grad=True diz para o PyTorch rastrear as operações nesse tensor x, assim, caso você queira o gradiente ele irá calcular para você.\n",
    "\n",
    "Basicamente, é assim que funciona:\n",
    "\n",
    "você cria seu tensor, seta requires_grad=True e executa operações nele.\n",
    "quando você terminar as operações, digite z.backward()\n",
    "\n",
    "O PyTorch sabe que os gradientes devem ser calculados em relação aos tensores que têm requires_grad=True. Quando chamamos z.backward(), estamos essencialmente dizendo ao PyTorch para calcular os gradientes de z em relação a todos os tensores que têm requires_grad=True.\n",
    "\n",
    "No exemplo fornecido, z é uma função da variável x (ou seja, z depende de x). Como x tem requires_grad=True, o PyTorch rastreia todas as operações realizadas em x para calcular z. Quando chamamos z.backward(), o PyTorch sabe que deve calcular os gradientes de z em relação a x, porque x foi usado para calcular z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3267, -1.4178],\n",
      "        [-1.1249,  1.0917]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad=True) \n",
    "# Cria um tensor x de forma (2,2) com valores aleatórios e define requires_grad=True para rastrear as operações nele.\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.7602, 2.0102],\n",
      "        [1.2654, 1.1918]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "#  Calcula o quadrado de cada elemento em x.\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x7fa218d12a10>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## grad_fn shows the function that generated this variable\n",
    "print(y.grad_fn)\n",
    "# Imprime a função que gerou y, que neste caso é a função de potência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5569, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "#  Calcula a média de todos os elementos em y.\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(x.grad)\n",
    "# Imprime os gradientes de x até este momento. Como nenhum cálculo de gradiente foi feito ainda, isso resultará em None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6634, -0.7089],\n",
      "        [-0.5625,  0.5459]])\n",
      "tensor([[ 0.6634, -0.7089],\n",
      "        [-0.5625,  0.5459]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward() # Calcula os gradientes de z em relação a x.\n",
    "print(x.grad) \n",
    "#  Imprime os gradientes de x após o cálculo. Isso agora terá valores, representando os gradientes de z em relação a x.\n",
    "print(x/2)\n",
    "#  Imprime x dividido por 2. Isso serve para verificarmos manualmente se os gradientes estão corretos. \n",
    "# Os gradientes calculados por backward() devem ser metade dos valores de x, \n",
    "# já que a média de y é calculada a partir de x ao quadrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Autograd together\n",
    "\n",
    "When we create a network with PyTorch, all of the parameters are initialized with `requires_grad = True`. This means that when we calculate the loss and call `loss.backward()`, the gradients for the parameters are calculated. These gradients are used to update the weights with gradient descent. Below you can see an example of calculating the gradients using a backwards pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logits = model(images)\n",
    "loss = criterion(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[ 0.0043,  0.0043,  0.0043,  ...,  0.0043,  0.0043,  0.0043],\n",
      "        [ 0.0006,  0.0006,  0.0006,  ...,  0.0006,  0.0006,  0.0006],\n",
      "        [-0.0009, -0.0009, -0.0009,  ..., -0.0009, -0.0009, -0.0009],\n",
      "        ...,\n",
      "        [ 0.0012,  0.0012,  0.0012,  ...,  0.0012,  0.0012,  0.0012],\n",
      "        [-0.0029, -0.0029, -0.0029,  ..., -0.0029, -0.0029, -0.0029],\n",
      "        [ 0.0004,  0.0004,  0.0004,  ...,  0.0004,  0.0004,  0.0004]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar esses gradientes para treinar nossa rede neural!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network!\n",
    "\n",
    "There's one last piece we need to start training, an optimizer that we'll use to update the weights with the gradients. We get these from PyTorch's [`optim` package](https://pytorch.org/docs/stable/optim.html). For example we can use stochastic gradient descent with `optim.SGD`. You can see how to define an optimizer below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know how to use all the individual parts so it's time to see how they work together. Let's consider just one learning step before looping through all the data. The general process with PyTorch:\n",
    "\n",
    "* Make a forward pass through the network \n",
    "* Use the network output to calculate the loss\n",
    "* Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
    "* Take a step with the optimizer to update the weights\n",
    "\n",
    "Below I'll go through one training step and print out the weights and gradients so you can see how it changes. Note that I have a line of code `optimizer.zero_grad()`. When you do multiple backwards passes with the same parameters, the gradients are accumulated. This means that you need to zero the gradients on each training pass or you'll retain gradients from previous training batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[ 0.0328, -0.0165, -0.0145,  ...,  0.0069, -0.0026,  0.0036],\n",
      "        [-0.0139, -0.0071,  0.0115,  ..., -0.0034, -0.0156, -0.0291],\n",
      "        [-0.0089,  0.0224, -0.0111,  ...,  0.0061,  0.0126, -0.0344],\n",
      "        ...,\n",
      "        [-0.0253, -0.0145,  0.0276,  ..., -0.0260, -0.0328, -0.0111],\n",
      "        [ 0.0255, -0.0068, -0.0173,  ..., -0.0134, -0.0036,  0.0016],\n",
      "        [ 0.0211, -0.0131, -0.0321,  ...,  0.0304, -0.0282, -0.0217]],\n",
      "       requires_grad=True)\n",
      "Gradient - tensor([[ 0.0006,  0.0006,  0.0006,  ...,  0.0006,  0.0006,  0.0006],\n",
      "        [-0.0047, -0.0047, -0.0047,  ..., -0.0047, -0.0047, -0.0047],\n",
      "        [-0.0026, -0.0026, -0.0026,  ..., -0.0026, -0.0026, -0.0026],\n",
      "        ...,\n",
      "        [-0.0009, -0.0009, -0.0009,  ..., -0.0009, -0.0009, -0.0009],\n",
      "        [-0.0018, -0.0018, -0.0018,  ..., -0.0018, -0.0018, -0.0018],\n",
      "        [ 0.0035,  0.0035,  0.0035,  ...,  0.0035,  0.0035,  0.0035]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# zera os gradientes antes de iniciar um novo passo de treinamento.\n",
    "# Isso é necessário porque os gradientes são acumulados a cada chamada de backward(), \n",
    "# e se não forem zerados, os gradientes acumulados de lotes anteriores afetarão os\n",
    "# cálculos de gradiente para lotes futuros.\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model(images) # MODEL DEFINIDO ANTES!\n",
    "loss = criterion(output, labels)\n",
    "# CRITERION (FUNÇÃO DE PERDA) DEFINIDO ANTES!\n",
    "# Calcula a perda (loss) usando as previsões do modelo (output) e os rótulos verdadeiros (labels). \n",
    "\n",
    "loss.backward()\n",
    "# Executa uma passagem para trás através da rede neural. \n",
    "# Isso calcula os gradientes de todas as variáveis que têm requires_grad=True com relação à perda (loss). \n",
    "# Esses gradientes são usados para atualizar os pesos da rede neural durante a etapa de otimização.\n",
    "\n",
    "print('Gradient -', model[0].weight.grad)\n",
    "# imprime os gradientes dos pesos da primeira camada linear da rede neural após a chamada \n",
    "# de backward(). Isso permite visualizar como os gradientes dos pesos estão mudando ao longo do\n",
    "# treinamento. Isso é útil para entender como os pesos estão sendo ajustados durante o treinamento da rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[ 0.0328, -0.0165, -0.0145,  ...,  0.0069, -0.0026,  0.0035],\n",
      "        [-0.0139, -0.0070,  0.0115,  ..., -0.0033, -0.0156, -0.0291],\n",
      "        [-0.0089,  0.0224, -0.0111,  ...,  0.0061,  0.0126, -0.0344],\n",
      "        ...,\n",
      "        [-0.0253, -0.0145,  0.0276,  ..., -0.0260, -0.0328, -0.0111],\n",
      "        [ 0.0255, -0.0068, -0.0173,  ..., -0.0134, -0.0036,  0.0016],\n",
      "        [ 0.0210, -0.0132, -0.0321,  ...,  0.0304, -0.0282, -0.0217]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Take an update step and view the new weights\n",
    "optimizer.step()\n",
    "# atualiza os pesos da rede neural usando o otimizador. \n",
    "# O otimizador ajusta os pesos com base nos gradientes calculados durante a passagem para trás.\n",
    "\n",
    "print('Updated weights - ', model[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training for real\n",
    "\n",
    "Now we'll put this algorithm into a loop so we can go through all the images. Some nomenclature, one pass through the entire dataset is called an *epoch*. So here we're going to loop through `trainloader` to get our training batches. For each batch, we'll be doing a training pass where we calculate the loss, do a backwards pass, and update the weights.\n",
    "\n",
    ">**Exercise:** Implement the training pass for our network. If you implemented it correctly, you should see the training loss drop with each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9395466408749888\n",
      "Training loss: 0.9106576813500065\n",
      "Training loss: 0.5522416554280182\n",
      "Training loss: 0.4411144864235097\n",
      "Training loss: 0.38859818743935015\n"
     ]
    }
   ],
   "source": [
    "## Your solution here\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the network trained, we can check out it's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x900 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
